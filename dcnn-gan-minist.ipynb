{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import  torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as td\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "定义变量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on  cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_works = 4\n",
    "batch_size = 256\n",
    "input_dim=100\n",
    "epochs = 1\n",
    "print(\"run on \",device.type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "\n",
    "# loading data\n",
    "def loading_minist_data(batch_siz:int, works:int)->(Iterable,Iterable):\n",
    "\n",
    "    train_set = torchvision.datasets.MNIST(root=\"./data\",train=True,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "    test_set = torchvision.datasets.MNIST(root=\"./data\",train=False,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "    return td.DataLoader(dataset=train_set, batch_size=batch_siz, shuffle=True, num_workers=works,drop_last=True), td.DataLoader(dataset=test_set, batch_size=batch_siz, shuffle=True, num_workers=works,drop_last=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # 28*28 -> (28 )/2 = 12*12\n",
    "            nn.Conv2d(1, 32,kernel_size=3,padding=1, stride=2,dtype=torch.float32),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            # 14,14 -> 7*7\n",
    "            nn.Conv2d(32,64,kernel_size=3,padding=1,stride=2,dtype=torch.float32),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            # 10 filters to 10 filters\n",
    "            # 7*7 -> 3*3\n",
    "            nn.Conv2d(64, 128, kernel_size=3,stride=2,dtype=torch.float32),\n",
    "            nn.LeakyReLU(0.02),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*3*3,10),\n",
    "            # nn.ReLU()\n",
    "            # nn.Linear(128,1),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "        self.cnt=0\n",
    "        self.loss_metric=[]\n",
    "        self.loss_func = nn.BCELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters())\n",
    "        pass\n",
    "    def forward(self,inputs):\n",
    "        for i in self.model:\n",
    "            # print(inputs.shape)\n",
    "            inputs = i(inputs)\n",
    "        return inputs\n",
    "        # return self.model(inputs)\n",
    "    def train(self,inputs,targets):\n",
    "        out = self.forward(inputs)\n",
    "\n",
    "        loss = self.loss_func(out,targets)\n",
    "        self.cnt+=1\n",
    "        self.loss_metric.append(loss.item())\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        pass\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,in_dim:int):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_dim, 200),\n",
    "            nn.LeakyReLU(0.02),\n",
    "            nn.LayerNorm(200),\n",
    "            nn.Linear(200, 784),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        # counter and accumulator for progress\n",
    "        self.cnt = 0\n",
    "        self.loss_metric = []\n",
    "\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        return self.model(inputs).view(batch_size,28,28)\n",
    "    def train(self,D:Discriminator,inputs,targets):\n",
    "        gen_out = self.forward(inputs)\n",
    "        # print(gen_out.shape)\n",
    "        d_out = D.forward(gen_out)\n",
    "\n",
    "        loss  = D.loss_func(d_out,targets)\n",
    "                # zero gradients, perform a backward pass, update weights\n",
    "        self.cnt+=1\n",
    "        self.loss_metric.append(loss.item())\n",
    "        self.optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimiser.step()\n",
    "\n",
    "def generate_random_seed(size):\n",
    "    random_data = torch.randn(size*batch_size).view(batch_size,size)\n",
    "    return random_data.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate nums is run on  cpu\n",
      "2.3368585109710693\n",
      "2.1489381790161133\n",
      "2.023455858230591\n",
      "1.9598240852355957\n",
      "1.8997929096221924\n",
      "1.8605726957321167\n",
      "1.8319669961929321\n",
      "1.8174470663070679\n",
      "1.761227011680603\n",
      "1.7657605409622192\n",
      "1.7399898767471313\n",
      "1.7435168027877808\n",
      "1.7090314626693726\n",
      "1.6886435747146606\n",
      "1.6749978065490723\n",
      "1.6808104515075684\n",
      "1.6753184795379639\n",
      "1.6733266115188599\n",
      "1.6503156423568726\n",
      "1.646734356880188\n",
      "1.6524083614349365\n",
      "1.6214808225631714\n",
      "1.6492966413497925\n",
      "1.6436840295791626\n",
      "1.6389973163604736\n",
      "1.601409912109375\n",
      "1.617828607559204\n",
      "1.5979033708572388\n",
      "1.5815285444259644\n",
      "1.5955071449279785\n",
      "1.5858880281448364\n",
      "1.602893590927124\n",
      "1.5752931833267212\n",
      "1.5841491222381592\n",
      "1.6161779165267944\n",
      "1.578624963760376\n",
      "1.6027278900146484\n",
      "1.5805777311325073\n",
      "1.60039484500885\n",
      "1.572749137878418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m<timed exec>:16\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "File \u001B[0;32m~/mambaforge/envs/py39/lib/python3.9/site-packages/torch/_tensor.py:307\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    300\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    301\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    305\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    306\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 307\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/py39/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retain_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    152\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m--> 154\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "G = Generator(input_dim)\n",
    "D = Discriminator()\n",
    "train_iter ,test_iter = loading_minist_data(batch_size,4)\n",
    "print(\"generate nums is run on \",generate_random_seed(input_dim).device)\n",
    "\n",
    "for k in range(epochs):\n",
    "\n",
    "    for it,y in train_iter:\n",
    "    # print(y)\n",
    "        out = D.forward(it)\n",
    "    # y = torch.reshape(y,out.shape)\n",
    "        loss = F.cross_entropy(out,y)\n",
    "        print(loss.item())\n",
    "    # print(loss)\n",
    "        D.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        D.optimizer.step()\n",
    "\n",
    "# output = G.forward(generate_random_seed(input_dim))\n",
    "# img = output.detach().numpy().reshape(28,28)\n",
    "# plt.imshow(output.cpu().detach().numpy()[0], interpolation='none', cmap='Blues')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "loss_metric = []\n",
    "cnt=0\n",
    "for it,y in test_iter:\n",
    "    out = D.forward(it)\n",
    "    loss = F.cross_entropy(out,y)\n",
    "    cnt+=1\n",
    "    if(cnt%10==0):\n",
    "        loss_metric.append(loss.item())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.492141842842102, 1.4767476320266724, 1.4831912517547607]\n"
     ]
    }
   ],
   "source": [
    "# print(loss_metric)\n",
    "# output = G.forward(generate_random_seed(input_dim))\n",
    "# img = output.detach().numpy().reshape(28,28)\n",
    "# plt.imshow(output.detach().numpy()[0], interpolation='none', cmap='Blues')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}